* Prepare stimuli
#+begin_src python :exports none :session words
  from pathlib import Path
  path_root = Path()
  path_words = path_root / ".." / "Instruments" / "Words" / "cleaned"
  path_words

  #+end_src

  #+RESULTS:
  : ../Instruments/Words/cleaned

** Spelling tests
*** Prepare words
    Prepare the words that will be used by the spelling tests.
**** Clean initial database
     This is done using stimpool which was developed for this project.

     #+begin_src python :exports both :session words :results output
       from stimpool.words import WordPool
     #+end_src

     #+RESULTS:

***** Get word pool
      This extracts the base word for each word by removing the suffix indicators.
     #+begin_src python :exports both :session words :results output
       word_pool = WordPool()
       print(word_pool.words.size)
       print(word_pool.words.head())
     #+end_src

     #+RESULTS:
     : 55457
     : 0           abs
     : 1          adsl
     : 2        adolfo
     : 3        adrián
     : 4    afganistán
     : Name: words, dtype: object

***** Select words without accented characters
      We don't want words that have accented characters because that adds a layer of complexity
      to spelling tasks because requires participants to press commands in order to type these
      characters.

      #+begin_src python :exports both :session words :results output
        word_pool.select_words_without_accented_characters()
        print(word_pool.words.size)
        print(word_pool.words.head())
      #+end_src

      #+RESULTS:
      : 46801
      : 0        abs
      : 1       adsl
      : 2     adolfo
      : 5    aguilar
      : 6      aitor
      : Name: words, dtype: object

***** Select words of more than 1 letter
      Just in case there are any

      #+begin_src python :exports both :session words :results output
        word_pool.select_words_of_length(min_len=2)
        print(word_pool.words.size)
        print(word_pool.words.head())
        path_word_pool_initial = path_words / "words_pool_initial"
        word_pool.save_pool(path_word_pool_initial)
      #+end_src

      #+RESULTS:
      : 46794
      : 0        abs
      : 1       adsl
      : 2     adolfo
      : 5    aguilar
      : 6      aitor
      : Name: words, dtype: object

***** Select a sample of 5,000 words
      This is sample will be analyzed in detail and then a subset will be selected.

      This sample was selected in a way that it is reproducible.

      #+begin_src python :exports both :session words :results output
        word_pool_sample = word_pool.sample_pool(n=5000)
        print(word_pool_sample.size)
        print(word_pool_sample.head())
        path_word_pool_sample_5000 = path_words / "words_pool_sample_5000"
        word_pool.save_pool(path_word_pool_sample_5000)
      #+end_src

      #+RESULTS:
      : 5000
      : 6215     atestiguar
      : 40259    penalmente
      : 6817        azoemia
      : 11728        chitar
      : 31861        ladero
      : Name: words, dtype: object

**** Word difficulty
***** Analyze word difficulty
      #+begin_src python :exports both :session words :results output
        from wdiff.analyzer import Analyzer
      #+end_src

      #+RESULTS:

      #+begin_src python :exports both :session words
        analyzer = Analyzer(word_pool_sample)
        analyzer.run_all_analyses()
        word_pool_analyzed = analyzer.results
        word_pool_analyzed
      #+end_src

      #+RESULTS:
      #+begin_example
                   text  length  silent_letters  shared_phonemes  total_difficulty
      0      atestiguar      10               0                1                11
      1      penalmente      10               0                0                10
      2         azoemia       7               0                1                 8
      3          chitar       6               0                0                 6
      4          ladero       6               0                0                 6
      ...           ...     ...             ...              ...               ...
      4995      racista       7               0                2                 9
      4996      triscar       7               0                2                 9
      4997    capadocio       9               0                2                11
      4998   encanallar      10               0                2                12
      4999  zampabollos      11               0                4                15

      [5000 rows x 5 columns]
      #+end_example

